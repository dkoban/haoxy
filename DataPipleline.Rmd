---
title: "Hoaxy Data Pipeline"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

The following document describes an automated workflow for the following tasks:

1. Collect Tweet data from Hoaxy
2. Enrich Twitter user accounts with profile information
3. Generate time series data for us in Vensim

## Load libraries and functions

```{r cars}
library(tidyverse)
library(stringr)
library(hoaxy)
library(RColorBrewer)
source("~/Documents/hoaxy/functions.R")
hoaxy_key('')
```

## Query Hoaxy for recent articles

```{r}
articles <- hx_latest_articles(past_hours = 30)
articles$tag <- extract_misinfo_tags(articles)
```

## Filter article list for likely misinformation stories

```{r}
misinfo_tags <- c("clickbait", "conspiracy", "junksci", 
                  "junkscience", "hoax", "fake")
articles <- articles %>% filter(tag %in% misinfo_tags)
articles$tag %>% table()
```

## Query an article or multiple articles for Hoaxy edges

```{r}
paste0(articles$tag[488], " - ", articles$title[488])
```

```{r}
edges <- hx_edges(articles$id[1], nodes_limit = 50000)
```

